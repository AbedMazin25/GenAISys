[
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 7.672140459219615,
      "median_latency": 3.9620336294174194,
      "p95_latency": 23.070408284664154,
      "p99_latency": 29.38224920034407,
      "min_latency": 1.05338716506958,
      "max_latency": 34.16046333312988,
      "requests_per_second": 0.1040660241719822,
      "avg_cpu": 3.024458204334365,
      "peak_cpu": 12.5,
      "avg_memory_mb": 1117.306283862229,
      "peak_memory_mb": 1120.4453125,
      "avg_gpu": 21.78018575851393,
      "peak_gpu": 100.0,
      "avg_power": 160.64947368421053,
      "peak_power": 182.83,
      "avg_correctness": 0.4791666666666667,
      "total_correct": 46.0,
      "accuracy_percentage": 47.91666666666667,
      "correctness_std": 0.4995657836784083,
      "total_tokens": 20172,
      "avg_tokens_per_response": 210.125,
      "tokens_per_second": 21.86687332913776
    },
    "timestamp": "2026-02-16T15:30:21.420848"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 5.737640957037608,
      "median_latency": 3.6097759008407593,
      "p95_latency": 19.92393660545349,
      "p99_latency": 36.842480707168576,
      "min_latency": 2.0024731159210205,
      "max_latency": 37.968374252319336,
      "requests_per_second": 0.17402323815121618,
      "avg_cpu": 2.5157068062827226,
      "peak_cpu": 5.2,
      "avg_memory_mb": 1733.3975785340315,
      "peak_memory_mb": 1785.8984375,
      "avg_gpu": 23.895287958115183,
      "peak_gpu": 44.0,
      "avg_power": 168.01314136125654,
      "peak_power": 181.94,
      "avg_correctness": 0.5520833333333334,
      "total_correct": 53.0,
      "accuracy_percentage": 55.208333333333336,
      "correctness_std": 0.49727992759500045,
      "total_tokens": 12432,
      "avg_tokens_per_response": 129.5,
      "tokens_per_second": 22.536009340582495
    },
    "timestamp": "2026-02-16T15:39:35.087267"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 6.731623555223147,
      "median_latency": 3.0187647342681885,
      "p95_latency": 32.6097691655159,
      "p99_latency": 38.34432637691498,
      "min_latency": 1.3541913032531738,
      "max_latency": 38.8434796333313,
      "requests_per_second": 0.14838165694142688,
      "avg_cpu": 3.2583333333333333,
      "peak_cpu": 7.4,
      "avg_memory_mb": 1743.5078125,
      "peak_memory_mb": 1743.5078125,
      "avg_gpu": 28.25,
      "peak_gpu": 96.0,
      "avg_power": 176.75162280701753,
      "peak_power": 204.77,
      "avg_correctness": 0.5520833333333334,
      "total_correct": 53.0,
      "accuracy_percentage": 55.208333333333336,
      "correctness_std": 0.49727992759500045,
      "total_tokens": 17267,
      "avg_tokens_per_response": 179.86458333333334,
      "tokens_per_second": 26.688604900079355
    },
    "timestamp": "2026-02-16T15:50:24.080653"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 8.015749953687191,
      "median_latency": 3.4397674798965454,
      "p95_latency": 37.82106614112854,
      "p99_latency": 39.76205785274505,
      "min_latency": 1.8733329772949219,
      "max_latency": 40.60691809654236,
      "requests_per_second": 0.12455786352761167,
      "avg_cpu": 3.4061818181818184,
      "peak_cpu": 6.9,
      "avg_memory_mb": 1762.3272585227273,
      "peak_memory_mb": 1797.55078125,
      "avg_gpu": 27.392727272727274,
      "peak_gpu": 64.0,
      "avg_power": 174.45890510948905,
      "peak_power": 210.7,
      "avg_correctness": 0.5416666666666666,
      "total_correct": 52.0,
      "accuracy_percentage": 54.166666666666664,
      "correctness_std": 0.4982608642958916,
      "total_tokens": 18622,
      "avg_tokens_per_response": 193.97916666666666,
      "tokens_per_second": 24.161630568866507
    },
    "timestamp": "2026-02-16T16:03:16.820966"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 23.007209512094658,
      "median_latency": 27.074233531951904,
      "p95_latency": 30.223640263080597,
      "p99_latency": 32.759410655498506,
      "min_latency": 8.17543649673462,
      "max_latency": 33.37792205810547,
      "requests_per_second": 0.04037739141792272,
      "avg_cpu": 3.1038798498122655,
      "peak_cpu": 9.8,
      "avg_memory_mb": 1822.0690364909262,
      "peak_memory_mb": 1824.46484375,
      "avg_gpu": 78.91489361702128,
      "peak_gpu": 100.0,
      "avg_power": 281.3631914893617,
      "peak_power": 299.81,
      "avg_correctness": 0.7708333333333334,
      "total_correct": 74.0,
      "accuracy_percentage": 77.08333333333334,
      "correctness_std": 0.420296687538167,
      "total_tokens": 79195,
      "avg_tokens_per_response": 824.9479166666666,
      "tokens_per_second": 33.309244930649896
    },
    "timestamp": "2026-02-16T16:44:07.085257"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 24.077835984528065,
      "median_latency": 28.306138038635254,
      "p95_latency": 31.800242722034454,
      "p99_latency": 32.933121943473814,
      "min_latency": 6.0988523960113525,
      "max_latency": 33.047091484069824,
      "requests_per_second": 0.041504897364236876,
      "avg_cpu": 3.1847741935483866,
      "peak_cpu": 20.3,
      "avg_memory_mb": 1864.0400403225806,
      "peak_memory_mb": 1869.625,
      "avg_gpu": 83.20387096774193,
      "peak_gpu": 95.0,
      "avg_power": 291.0032,
      "peak_power": 299.44,
      "avg_correctness": 0.7083333333333334,
      "total_correct": 68.0,
      "accuracy_percentage": 70.83333333333334,
      "correctness_std": 0.45452967144315476,
      "total_tokens": 79241,
      "avg_tokens_per_response": 825.4270833333334,
      "tokens_per_second": 34.2592663754114
    },
    "timestamp": "2026-02-16T17:22:42.090840"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 23.4668081899484,
      "median_latency": 27.574841499328613,
      "p95_latency": 30.001764953136444,
      "p99_latency": 31.989807355403897,
      "min_latency": 5.812826871871948,
      "max_latency": 32.764673709869385,
      "requests_per_second": 0.042575542800473064,
      "avg_cpu": 2.95,
      "peak_cpu": 4.8,
      "avg_memory_mb": 1874.515625,
      "peak_memory_mb": 1874.515625,
      "avg_gpu": 82.75,
      "peak_gpu": 91.0,
      "avg_power": 293.39125,
      "peak_power": 298.88,
      "avg_correctness": 0.7604166666666666,
      "total_correct": 73.0,
      "accuracy_percentage": 76.04166666666666,
      "correctness_std": 0.42682919267808084,
      "total_tokens": 80859,
      "avg_tokens_per_response": 842.28125,
      "tokens_per_second": 35.860581409410955
    },
    "timestamp": "2026-02-16T18:00:18.926501"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 25.448906200627487,
      "median_latency": 28.599925756454468,
      "p95_latency": 30.368461310863495,
      "p99_latency": 32.71280752420425,
      "min_latency": 6.108747243881226,
      "max_latency": 34.45886182785034,
      "requests_per_second": 0.039262245840473387,
      "avg_cpu": 2.9421052631578943,
      "peak_cpu": 4.3,
      "avg_memory_mb": 1876.8384046052631,
      "peak_memory_mb": 1880.0390625,
      "avg_gpu": 81.84210526315789,
      "peak_gpu": 93.0,
      "avg_power": 286.47210526315786,
      "peak_power": 298.73,
      "avg_correctness": 0.71875,
      "total_correct": 69.0,
      "accuracy_percentage": 71.875,
      "correctness_std": 0.4496092053105675,
      "total_tokens": 84338,
      "avg_tokens_per_response": 878.5208333333334,
      "tokens_per_second": 34.49270093431088
    },
    "timestamp": "2026-02-16T18:41:06.056295"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 24.36153755337,
      "median_latency": 27.40629005432129,
      "p95_latency": 30.207709074020386,
      "p99_latency": 31.201427054405208,
      "min_latency": 8.630735635757446,
      "max_latency": 32.6806800365448,
      "requests_per_second": 0.04101318789748655,
      "avg_cpu": 3.7911314984709477,
      "peak_cpu": 7.6,
      "avg_memory_mb": 1885.8046875,
      "peak_memory_mb": 1885.8046875,
      "avg_gpu": 88.86850152905198,
      "peak_gpu": 100.0,
      "avg_power": 296.9758409785932,
      "peak_power": 299.49,
      "avg_correctness": 0.8333333333333334,
      "total_correct": 80.0,
      "accuracy_percentage": 83.33333333333334,
      "correctness_std": 0.37267799624996495,
      "total_tokens": 84352,
      "avg_tokens_per_response": 878.6666666666666,
      "tokens_per_second": 36.03692109925819
    },
    "timestamp": "2026-02-16T19:20:08.791244"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 27.353074739376705,
      "median_latency": 29.433292746543884,
      "p95_latency": 32.594842970371246,
      "p99_latency": 34.58270837068557,
      "min_latency": 10.281709432601929,
      "max_latency": 35.437673807144165,
      "requests_per_second": 0.036531101599666105,
      "avg_cpu": 4.396296296296296,
      "peak_cpu": 26.3,
      "avg_memory_mb": 1880.7892700785023,
      "peak_memory_mb": 1890.171875,
      "avg_gpu": 84.4122383252818,
      "peak_gpu": 100.0,
      "avg_power": 289.1874718196457,
      "peak_power": 299.11,
      "avg_correctness": 0.7916666666666666,
      "total_correct": 76.0,
      "accuracy_percentage": 79.16666666666666,
      "correctness_std": 0.4061164310337068,
      "total_tokens": 88442,
      "avg_tokens_per_response": 921.2708333333334,
      "tokens_per_second": 33.655038413309065
    },
    "timestamp": "2026-02-16T20:03:58.722159"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 26.675165742635727,
      "median_latency": 28.208362936973572,
      "p95_latency": 31.1950141787529,
      "p99_latency": 33.00173282623291,
      "min_latency": 5.53114914894104,
      "max_latency": 33.08147358894348,
      "requests_per_second": 0.03745874997089271,
      "avg_cpu": 3.9286755771567434,
      "peak_cpu": 8.7,
      "avg_memory_mb": 1895.66015625,
      "peak_memory_mb": 1895.66015625,
      "avg_gpu": 88.41069258809235,
      "peak_gpu": 97.0,
      "avg_power": 295.50336573511544,
      "peak_power": 299.49,
      "avg_correctness": 0.7916666666666666,
      "total_correct": 76.0,
      "accuracy_percentage": 79.16666666666666,
      "correctness_std": 0.4061164310337068,
      "total_tokens": 91035,
      "avg_tokens_per_response": 948.28125,
      "tokens_per_second": 35.52143024583561
    },
    "timestamp": "2026-02-16T20:46:43.572215"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 28.192479739586513,
      "median_latency": 30.44258737564087,
      "p95_latency": 33.27463525533676,
      "p99_latency": 34.784999668598175,
      "min_latency": 6.34376859664917,
      "max_latency": 35.08009099960327,
      "requests_per_second": 0.03544422840445273,
      "avg_cpu": 4.195785876993166,
      "peak_cpu": 11.4,
      "avg_memory_mb": 1893.1207511745445,
      "peak_memory_mb": 1902.640625,
      "avg_gpu": 83.45671981776765,
      "peak_gpu": 100.0,
      "avg_power": 286.21847380410026,
      "peak_power": 299.55,
      "avg_correctness": 0.8229166666666666,
      "total_correct": 79.0,
      "accuracy_percentage": 82.29166666666666,
      "correctness_std": 0.3817392125376811,
      "total_tokens": 88399,
      "avg_tokens_per_response": 920.8229166666666,
      "tokens_per_second": 32.637857778387676
    },
    "timestamp": "2026-02-16T21:31:54.086015"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 13.172132849693298,
      "median_latency": 7.430198907852173,
      "p95_latency": 28.655067086219788,
      "p99_latency": 29.40903006792068,
      "min_latency": 1.9195811748504639,
      "max_latency": 31.79982352256775,
      "requests_per_second": 0.06805200645486895,
      "avg_cpu": 4.050219298245614,
      "peak_cpu": 8.0,
      "avg_memory_mb": 1889.9064555921052,
      "peak_memory_mb": 1890.35546875,
      "avg_gpu": 77.42105263157895,
      "peak_gpu": 95.0,
      "avg_power": 272.9068859649123,
      "peak_power": 299.24,
      "avg_correctness": 0.71875,
      "total_correct": 69.0,
      "accuracy_percentage": 71.875,
      "correctness_std": 0.4496092053105675,
      "total_tokens": 47439,
      "avg_tokens_per_response": 494.15625,
      "tokens_per_second": 33.628324314713836
    },
    "timestamp": "2026-02-16T21:56:46.782549"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 15.416459679603577,
      "median_latency": 11.720682621002197,
      "p95_latency": 28.947429418563843,
      "p99_latency": 30.360602903366082,
      "min_latency": 2.843705892562866,
      "max_latency": 31.938150882720947,
      "requests_per_second": 0.06477813744849664,
      "avg_cpu": 4.074460431654677,
      "peak_cpu": 8.6,
      "avg_memory_mb": 1884.1919542491007,
      "peak_memory_mb": 1891.4921875,
      "avg_gpu": 84.06115107913669,
      "peak_gpu": 97.0,
      "avg_power": 287.74258992805755,
      "peak_power": 299.48,
      "avg_correctness": 0.6979166666666666,
      "total_correct": 67.0,
      "accuracy_percentage": 69.79166666666666,
      "correctness_std": 0.45916118417779567,
      "total_tokens": 52846,
      "avg_tokens_per_response": 550.4791666666666,
      "tokens_per_second": 35.659015120867224
    },
    "timestamp": "2026-02-16T22:21:30.772762"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 18.049020166198414,
      "median_latency": 26.750521659851074,
      "p95_latency": 29.65190762281418,
      "p99_latency": 30.452269959449765,
      "min_latency": 2.0355913639068604,
      "max_latency": 30.851203441619873,
      "requests_per_second": 0.05538524234172253,
      "avg_cpu": 4.701798561151079,
      "peak_cpu": 11.1,
      "avg_memory_mb": 1901.0760173111512,
      "peak_memory_mb": 1902.19140625,
      "avg_gpu": 87.04676258992805,
      "peak_gpu": 100.0,
      "avg_power": 292.65129496402875,
      "peak_power": 298.55,
      "avg_correctness": 0.7083333333333334,
      "total_correct": 68.0,
      "accuracy_percentage": 70.83333333333334,
      "correctness_std": 0.45452967144315476,
      "total_tokens": 63525,
      "avg_tokens_per_response": 661.71875,
      "tokens_per_second": 36.64945333081171
    },
    "timestamp": "2026-02-16T22:50:26.096327"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 19.100188950697582,
      "median_latency": 27.67568278312683,
      "p95_latency": 30.764886379241943,
      "p99_latency": 32.06915053129196,
      "min_latency": 3.3113956451416016,
      "max_latency": 32.627233266830444,
      "requests_per_second": 0.05229841100447955,
      "avg_cpu": 4.263394342762064,
      "peak_cpu": 8.8,
      "avg_memory_mb": 1888.3342931052412,
      "peak_memory_mb": 1908.3359375,
      "avg_gpu": 84.94675540765391,
      "peak_gpu": 100.0,
      "avg_power": 287.8078535773711,
      "peak_power": 299.1,
      "avg_correctness": 0.71875,
      "total_correct": 69.0,
      "accuracy_percentage": 71.875,
      "correctness_std": 0.4496092053105675,
      "total_tokens": 64062,
      "avg_tokens_per_response": 667.3125,
      "tokens_per_second": 34.89938339342676
    },
    "timestamp": "2026-02-16T23:21:03.722267"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 20.480452366173267,
      "median_latency": 27.400196075439453,
      "p95_latency": 29.64115458726883,
      "p99_latency": 31.25466065406799,
      "min_latency": 2.2969107627868652,
      "max_latency": 32.22453808784485,
      "requests_per_second": 0.04879660556544007,
      "avg_cpu": 4.373570324574961,
      "peak_cpu": 11.1,
      "avg_memory_mb": 1893.6999492851623,
      "peak_memory_mb": 1894.9140625,
      "avg_gpu": 89.94281298299846,
      "peak_gpu": 97.0,
      "avg_power": 294.2393199381762,
      "peak_power": 299.08,
      "avg_correctness": 0.75,
      "total_correct": 72.0,
      "accuracy_percentage": 75.0,
      "correctness_std": 0.4330127018922193,
      "total_tokens": 71857,
      "avg_tokens_per_response": 748.5104166666666,
      "tokens_per_second": 36.52476756370653
    },
    "timestamp": "2026-02-16T23:53:53.080939"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 22.731196343898773,
      "median_latency": 29.07831597328186,
      "p95_latency": 30.81460350751877,
      "p99_latency": 31.245837390422817,
      "min_latency": 3.6383917331695557,
      "max_latency": 31.918547868728638,
      "requests_per_second": 0.04395208684509145,
      "avg_cpu": 4.630758426966292,
      "peak_cpu": 9.7,
      "avg_memory_mb": 1891.473907127809,
      "peak_memory_mb": 1896.3515625,
      "avg_gpu": 85.18679775280899,
      "peak_gpu": 100.0,
      "avg_power": 289.17735955056173,
      "peak_power": 300.15,
      "avg_correctness": 0.7604166666666666,
      "total_correct": 73.0,
      "accuracy_percentage": 76.04166666666666,
      "correctness_std": 0.42682919267808084,
      "total_tokens": 74616,
      "avg_tokens_per_response": 777.25,
      "tokens_per_second": 34.16175950034733
    },
    "timestamp": "2026-02-17T00:30:19.284147"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 24.80712828040123,
      "median_latency": 28.99318218231201,
      "p95_latency": 30.624727368354797,
      "p99_latency": 31.535331428050988,
      "min_latency": 2.5368568897247314,
      "max_latency": 33.626198053359985,
      "requests_per_second": 0.04027720829633261,
      "avg_cpu": 5.337723785166241,
      "peak_cpu": 11.3,
      "avg_memory_mb": 1891.75,
      "peak_memory_mb": 1891.75,
      "avg_gpu": 91.60358056265984,
      "peak_gpu": 96.0,
      "avg_power": 297.0585147247119,
      "peak_power": 299.32,
      "avg_correctness": 0.7083333333333334,
      "total_correct": 68.0,
      "accuracy_percentage": 70.83333333333334,
      "correctness_std": 0.45452967144315476,
      "total_tokens": 82947,
      "avg_tokens_per_response": 864.03125,
      "tokens_per_second": 34.80076663079063
    },
    "timestamp": "2026-02-17T01:10:04.772813"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 25.421696161230404,
      "median_latency": 31.51477861404419,
      "p95_latency": 32.59393411874771,
      "p99_latency": 33.411600935459134,
      "min_latency": 5.1290953159332275,
      "max_latency": 33.728124380111694,
      "requests_per_second": 0.03930424586658781,
      "avg_cpu": 6.320879120879121,
      "peak_cpu": 11.7,
      "avg_memory_mb": 1887.5775955815018,
      "peak_memory_mb": 1891.48046875,
      "avg_gpu": 84.66849816849818,
      "peak_gpu": 100.0,
      "avg_power": 285.1503846153846,
      "peak_power": 299.25,
      "avg_correctness": 0.7083333333333334,
      "total_correct": 68.0,
      "accuracy_percentage": 70.83333333333334,
      "correctness_std": 0.45452967144315476,
      "total_tokens": 76699,
      "avg_tokens_per_response": 798.9479166666666,
      "tokens_per_second": 31.402045351264775
    },
    "timestamp": "2026-02-17T01:50:49.263836"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 3.4762075866262117,
      "median_latency": 2.510709285736084,
      "p95_latency": 9.881591260433197,
      "p99_latency": 13.275967657566065,
      "min_latency": 0.5994620323181152,
      "max_latency": 15.252763271331787,
      "requests_per_second": 0.20047662923028606,
      "avg_cpu": 5.866666666666668,
      "peak_cpu": 8.8,
      "avg_memory_mb": 1887.32421875,
      "peak_memory_mb": 1887.32421875,
      "avg_gpu": 58.36477987421384,
      "peak_gpu": 93.0,
      "avg_power": 232.63547169811318,
      "peak_power": 299.46,
      "avg_correctness": 0.46875,
      "total_correct": 45.0,
      "accuracy_percentage": 46.875,
      "correctness_std": 0.4990224819584785,
      "total_tokens": 12575,
      "avg_tokens_per_response": 130.98958333333334,
      "tokens_per_second": 26.260350130946325
    },
    "timestamp": "2026-02-17T02:00:02.399160"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 4.72481682151556,
      "median_latency": 3.4066624641418457,
      "p95_latency": 9.196795880794525,
      "p99_latency": 28.76120011806487,
      "min_latency": 2.0852742195129395,
      "max_latency": 32.13668870925903,
      "requests_per_second": 0.21099560097956205,
      "avg_cpu": 5.716447368421052,
      "peak_cpu": 15.4,
      "avg_memory_mb": 1880.0594675164473,
      "peak_memory_mb": 1892.82421875,
      "avg_gpu": 70.50657894736842,
      "peak_gpu": 94.0,
      "avg_power": 265.48828947368423,
      "peak_power": 299.1,
      "avg_correctness": 0.3229166666666667,
      "total_correct": 31.0,
      "accuracy_percentage": 32.29166666666667,
      "correctness_std": 0.46759116015548835,
      "total_tokens": 12623,
      "avg_tokens_per_response": 131.48958333333334,
      "tokens_per_second": 27.743723657968875
    },
    "timestamp": "2026-02-17T02:07:39.391143"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 12.966777754326662,
      "median_latency": 4.932269334793091,
      "p95_latency": 27.74994534254074,
      "p99_latency": 29.322811710834497,
      "min_latency": 1.4881088733673096,
      "max_latency": 31.6906156539917,
      "requests_per_second": 0.07699633926997926,
      "avg_cpu": 4.507773851590105,
      "peak_cpu": 15.2,
      "avg_memory_mb": 1892.08984375,
      "peak_memory_mb": 1892.08984375,
      "avg_gpu": 88.7773851590106,
      "peak_gpu": 96.0,
      "avg_power": 296.07809187279156,
      "peak_power": 299.38,
      "avg_correctness": 0.34375,
      "total_correct": 33.0,
      "accuracy_percentage": 34.375,
      "correctness_std": 0.47495887979908324,
      "total_tokens": 47102,
      "avg_tokens_per_response": 490.6458333333333,
      "tokens_per_second": 37.77793304473503
    },
    "timestamp": "2026-02-17T02:28:28.209851"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 10.656627910832563,
      "median_latency": 4.608084559440613,
      "p95_latency": 29.416878402233124,
      "p99_latency": 32.392630052566524,
      "min_latency": 2.204730272293091,
      "max_latency": 32.971792697906494,
      "requests_per_second": 0.09365491629121973,
      "avg_cpu": 4.357275541795666,
      "peak_cpu": 8.5,
      "avg_memory_mb": 1888.6105359907122,
      "peak_memory_mb": 1894.96875,
      "avg_gpu": 80.83281733746131,
      "peak_gpu": 100.0,
      "avg_power": 283.2956965944273,
      "peak_power": 299.67,
      "avg_correctness": 0.3645833333333333,
      "total_correct": 35.0,
      "accuracy_percentage": 36.45833333333333,
      "correctness_std": 0.4813131271728301,
      "total_tokens": 33968,
      "avg_tokens_per_response": 353.8333333333333,
      "tokens_per_second": 33.13823121437658
    },
    "timestamp": "2026-02-17T02:45:35.259533"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 20.04852071404457,
      "median_latency": 27.3641220331192,
      "p95_latency": 30.660503685474396,
      "p99_latency": 33.039126539230345,
      "min_latency": 1.3550679683685303,
      "max_latency": 33.06020712852478,
      "requests_per_second": 0.04982716199248698,
      "avg_cpu": 4.44021052631579,
      "peak_cpu": 7.7,
      "avg_memory_mb": 1891.49609375,
      "peak_memory_mb": 1891.49609375,
      "avg_gpu": 87.75157894736842,
      "peak_gpu": 97.0,
      "avg_power": 295.1496842105263,
      "peak_power": 299.72,
      "avg_correctness": 0.34375,
      "total_correct": 33.0,
      "accuracy_percentage": 34.375,
      "correctness_std": 0.47495887979908324,
      "total_tokens": 69128,
      "avg_tokens_per_response": 720.0833333333334,
      "tokens_per_second": 35.87970889809
    },
    "timestamp": "2026-02-17T03:17:43.930973"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 17.8065057421724,
      "median_latency": 28.59353816509247,
      "p95_latency": 30.561534345149994,
      "p99_latency": 31.959672141075128,
      "min_latency": 2.8601009845733643,
      "max_latency": 33.87339925765991,
      "requests_per_second": 0.05609353645567891,
      "avg_cpu": 4.280952380952381,
      "peak_cpu": 6.7,
      "avg_memory_mb": 1889.733630952381,
      "peak_memory_mb": 1893.58203125,
      "avg_gpu": 82.13492063492063,
      "peak_gpu": 100.0,
      "avg_power": 285.8642063492065,
      "peak_power": 299.47,
      "avg_correctness": 0.3541666666666667,
      "total_correct": 34.0,
      "accuracy_percentage": 35.41666666666667,
      "correctness_std": 0.4782600118020415,
      "total_tokens": 57249,
      "avg_tokens_per_response": 596.34375,
      "tokens_per_second": 33.45102988074127
    },
    "timestamp": "2026-02-17T03:46:17.364551"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 24.395139177640278,
      "median_latency": 29.230690836906433,
      "p95_latency": 31.90156388282776,
      "p99_latency": 33.81563279628754,
      "min_latency": 1.0019967555999756,
      "max_latency": 34.05680704116821,
      "requests_per_second": 0.04095673880967308,
      "avg_cpu": 4.893850267379679,
      "peak_cpu": 26.1,
      "avg_memory_mb": 1898.2890625,
      "peak_memory_mb": 1898.2890625,
      "avg_gpu": 90.3409090909091,
      "peak_gpu": 97.0,
      "avg_power": 295.96930481283425,
      "peak_power": 299.71,
      "avg_correctness": 0.3333333333333333,
      "total_correct": 32.0,
      "accuracy_percentage": 33.33333333333333,
      "correctness_std": 0.47140452079103173,
      "total_tokens": 80302,
      "avg_tokens_per_response": 836.4791666666666,
      "tokens_per_second": 34.25945874889966
    },
    "timestamp": "2026-02-17T04:25:23.312194"
  },
  {
    "framework": "llamaindex",
    "framework_name": "LlamaIndex",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 22.608079763750236,
      "median_latency": 31.52086091041565,
      "p95_latency": 33.243211686611176,
      "p99_latency": 34.50911314487457,
      "min_latency": 4.058335304260254,
      "max_latency": 34.94228672981262,
      "requests_per_second": 0.04419891727256464,
      "avg_cpu": 5.520893371757925,
      "peak_cpu": 11.9,
      "avg_memory_mb": 1892.0716127071325,
      "peak_memory_mb": 1896.54296875,
      "avg_gpu": 82.78242074927954,
      "peak_gpu": 100.0,
      "avg_power": 282.99541786743515,
      "peak_power": 299.58,
      "avg_correctness": 0.3333333333333333,
      "total_correct": 32.0,
      "accuracy_percentage": 33.33333333333333,
      "correctness_std": 0.47140452079103173,
      "total_tokens": 66477,
      "avg_tokens_per_response": 692.46875,
      "tokens_per_second": 30.606368995086246
    },
    "timestamp": "2026-02-17T05:01:37.324309"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 8.123887869218985,
      "median_latency": 3.9711880683898926,
      "p95_latency": 23.97446918487549,
      "p99_latency": 33.13361855745314,
      "min_latency": 1.2379536628723145,
      "max_latency": 38.111778020858765,
      "requests_per_second": 0.1074008446453631,
      "avg_cpu": 3.8953177257525087,
      "peak_cpu": 11.2,
      "avg_memory_mb": 1894.23828125,
      "peak_memory_mb": 1894.23828125,
      "avg_gpu": 21.82274247491639,
      "peak_gpu": 33.0,
      "avg_power": 173.02434782608697,
      "peak_power": 200.88,
      "avg_correctness": 0.4791666666666667,
      "total_correct": 46.0,
      "accuracy_percentage": 47.91666666666667,
      "correctness_std": 0.4995657836784083,
      "total_tokens": 20172,
      "avg_tokens_per_response": 210.125,
      "tokens_per_second": 22.56760248110692
    },
    "timestamp": "2026-02-17T05:17:45.090740"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 5.912872701883316,
      "median_latency": 3.496148943901062,
      "p95_latency": 20.093812584877014,
      "p99_latency": 41.04656995534895,
      "min_latency": 2.0935730934143066,
      "max_latency": 46.269309282302856,
      "requests_per_second": 0.16872486176838403,
      "avg_cpu": 2.685863874345549,
      "peak_cpu": 4.5,
      "avg_memory_mb": 1892.0511902814137,
      "peak_memory_mb": 1902.62109375,
      "avg_gpu": 21.80628272251309,
      "peak_gpu": 31.0,
      "avg_power": 174.27638743455498,
      "peak_power": 201.45,
      "avg_correctness": 0.5520833333333334,
      "total_correct": 53.0,
      "accuracy_percentage": 55.208333333333336,
      "correctness_std": 0.49727992759500045,
      "total_tokens": 12432,
      "avg_tokens_per_response": 129.5,
      "tokens_per_second": 21.849869599005732
    },
    "timestamp": "2026-02-17T05:27:16.080135"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 6.7681243270635605,
      "median_latency": 2.830649495124817,
      "p95_latency": 33.784768521785736,
      "p99_latency": 38.10895746946335,
      "min_latency": 1.2746973037719727,
      "max_latency": 38.71749210357666,
      "requests_per_second": 0.1474668183256441,
      "avg_cpu": 3.1939814814814818,
      "peak_cpu": 6.1,
      "avg_memory_mb": 1902.62109375,
      "peak_memory_mb": 1902.62109375,
      "avg_gpu": 27.5,
      "peak_gpu": 68.0,
      "avg_power": 183.18231481481482,
      "peak_power": 200.74,
      "avg_correctness": 0.5520833333333334,
      "total_correct": 53.0,
      "accuracy_percentage": 55.208333333333336,
      "correctness_std": 0.49727992759500045,
      "total_tokens": 17267,
      "avg_tokens_per_response": 179.86458333333334,
      "tokens_per_second": 26.52405783363434
    },
    "timestamp": "2026-02-17T05:38:09.089814"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 8.208451390266418,
      "median_latency": 3.580625057220459,
      "p95_latency": 38.20298832654953,
      "p99_latency": 39.84778488874435,
      "min_latency": 2.0819613933563232,
      "max_latency": 40.84781527519226,
      "requests_per_second": 0.12151699895189799,
      "avg_cpu": 3.3852791878172583,
      "peak_cpu": 5.2,
      "avg_memory_mb": 1901.250198286802,
      "peak_memory_mb": 1906.90625,
      "avg_gpu": 25.80710659898477,
      "peak_gpu": 63.0,
      "avg_power": 173.9351269035533,
      "peak_power": 203.77,
      "avg_correctness": 0.5416666666666666,
      "total_correct": 52.0,
      "accuracy_percentage": 54.166666666666664,
      "correctness_std": 0.4982608642958916,
      "total_tokens": 18622,
      "avg_tokens_per_response": 193.97916666666666,
      "tokens_per_second": 23.57176619252338
    },
    "timestamp": "2026-02-17T05:51:21.119355"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 22.855642358462017,
      "median_latency": 27.27472174167633,
      "p95_latency": 29.415005564689636,
      "p99_latency": 30.22779198884964,
      "min_latency": 8.121432542800903,
      "max_latency": 30.46965456008911,
      "requests_per_second": 0.04159367329128868,
      "avg_cpu": 2.888748241912799,
      "peak_cpu": 9.6,
      "avg_memory_mb": 1902.2689983298171,
      "peak_memory_mb": 1905.33984375,
      "avg_gpu": 82.00985915492957,
      "peak_gpu": 100.0,
      "avg_power": 285.3971308016878,
      "peak_power": 300.1,
      "avg_correctness": 0.7708333333333334,
      "total_correct": 74.0,
      "accuracy_percentage": 77.08333333333334,
      "correctness_std": 0.420296687538167,
      "total_tokens": 79195,
      "avg_tokens_per_response": 824.9479166666666,
      "tokens_per_second": 34.31261412816257
    },
    "timestamp": "2026-02-17T06:31:02.409763"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 23.913312767942745,
      "median_latency": 28.1434508562088,
      "p95_latency": 31.97019386291504,
      "p99_latency": 32.27035952806472,
      "min_latency": 6.270378589630127,
      "max_latency": 32.6108717918396,
      "requests_per_second": 0.04178127350229284,
      "avg_cpu": 3.2471801925722144,
      "peak_cpu": 7.3,
      "avg_memory_mb": 1941.0327705897523,
      "peak_memory_mb": 1990.24609375,
      "avg_gpu": 83.86107290233838,
      "peak_gpu": 98.0,
      "avg_power": 291.13997248968366,
      "peak_power": 299.85,
      "avg_correctness": 0.7083333333333334,
      "total_correct": 68.0,
      "accuracy_percentage": 70.83333333333334,
      "correctness_std": 0.45452967144315476,
      "total_tokens": 79241,
      "avg_tokens_per_response": 825.4270833333334,
      "tokens_per_second": 34.487394724949866
    },
    "timestamp": "2026-02-17T07:09:22.116575"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 23.697896495461464,
      "median_latency": 27.6270409822464,
      "p95_latency": 30.400063693523407,
      "p99_latency": 32.99172333478927,
      "min_latency": 5.854238510131836,
      "max_latency": 33.98883008956909,
      "requests_per_second": 0.04217524759074764,
      "avg_cpu": 2.7264663805436338,
      "peak_cpu": 6.2,
      "avg_memory_mb": 1940.484375,
      "peak_memory_mb": 1940.484375,
      "avg_gpu": 85.87982832618026,
      "peak_gpu": 96.0,
      "avg_power": 295.1299284692418,
      "peak_power": 299.78,
      "avg_correctness": 0.7604166666666666,
      "total_correct": 73.0,
      "accuracy_percentage": 76.04166666666666,
      "correctness_std": 0.42682919267808084,
      "total_tokens": 80859,
      "avg_tokens_per_response": 842.28125,
      "tokens_per_second": 35.523420259794406
    },
    "timestamp": "2026-02-17T07:47:20.368250"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 25.82293926427762,
      "median_latency": 28.98118793964386,
      "p95_latency": 31.367469489574432,
      "p99_latency": 32.61379557847976,
      "min_latency": 5.907693147659302,
      "max_latency": 35.43414092063904,
      "requests_per_second": 0.038698964971799324,
      "avg_cpu": 2.824342105263158,
      "peak_cpu": 9.9,
      "avg_memory_mb": 1940.8177066200658,
      "peak_memory_mb": 1945.859375,
      "avg_gpu": 83.12894736842105,
      "peak_gpu": 100.0,
      "avg_power": 291.14953947368423,
      "peak_power": 299.64,
      "avg_correctness": 0.71875,
      "total_correct": 69.0,
      "accuracy_percentage": 71.875,
      "correctness_std": 0.4496092053105675,
      "total_tokens": 84338,
      "avg_tokens_per_response": 878.5208333333334,
      "tokens_per_second": 33.99784695616262
    },
    "timestamp": "2026-02-17T08:28:43.082278"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 24.54945275435845,
      "median_latency": 27.6680805683136,
      "p95_latency": 29.590058088302612,
      "p99_latency": 30.144938313961024,
      "min_latency": 8.553151607513428,
      "max_latency": 31.36764669418335,
      "requests_per_second": 0.0406995337073152,
      "avg_cpu": 2.129179331306991,
      "peak_cpu": 5.9,
      "avg_memory_mb": 1949.859375,
      "peak_memory_mb": 1949.859375,
      "avg_gpu": 87.36626139817629,
      "peak_gpu": 98.0,
      "avg_power": 296.1613981762918,
      "peak_power": 300.05,
      "avg_correctness": 0.8333333333333334,
      "total_correct": 80.0,
      "accuracy_percentage": 83.33333333333334,
      "correctness_std": 0.37267799624996495,
      "total_tokens": 84352,
      "avg_tokens_per_response": 878.6666666666666,
      "tokens_per_second": 35.76132361749429
    },
    "timestamp": "2026-02-17T09:08:03.861369"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 27.550533585250378,
      "median_latency": 29.74284553527832,
      "p95_latency": 31.54068374633789,
      "p99_latency": 32.11472306251525,
      "min_latency": 10.327887535095215,
      "max_latency": 33.46361804008484,
      "requests_per_second": 0.03626948293403103,
      "avg_cpu": 2.1398058252427186,
      "peak_cpu": 5.6,
      "avg_memory_mb": 1965.2257376365292,
      "peak_memory_mb": 2032.25,
      "avg_gpu": 82.94660194174757,
      "peak_gpu": 100.0,
      "avg_power": 288.5356553398058,
      "peak_power": 300.06,
      "avg_correctness": 0.7916666666666666,
      "total_correct": 76.0,
      "accuracy_percentage": 79.16666666666666,
      "correctness_std": 0.4061164310337068,
      "total_tokens": 88442,
      "avg_tokens_per_response": 921.2708333333334,
      "tokens_per_second": 33.41401676720388
    },
    "timestamp": "2026-02-17T09:52:12.745089"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 26.753158231576283,
      "median_latency": 28.578424215316772,
      "p95_latency": 30.251689732074738,
      "p99_latency": 32.639647078514095,
      "min_latency": 4.6813390254974365,
      "max_latency": 34.419312953948975,
      "requests_per_second": 0.037378627228625956,
      "avg_cpu": 2.184605433376455,
      "peak_cpu": 5.9,
      "avg_memory_mb": 2013.25,
      "peak_memory_mb": 2013.25,
      "avg_gpu": 88.38809831824062,
      "peak_gpu": 97.0,
      "avg_power": 296.5201940491591,
      "peak_power": 299.83,
      "avg_correctness": 0.7916666666666666,
      "total_correct": 76.0,
      "accuracy_percentage": 79.16666666666666,
      "correctness_std": 0.4061164310337068,
      "total_tokens": 91035,
      "avg_tokens_per_response": 948.28125,
      "tokens_per_second": 35.44545135164546
    },
    "timestamp": "2026-02-17T10:35:03.084242"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 28.26406979560852,
      "median_latency": 30.64973247051239,
      "p95_latency": 32.35553312301636,
      "p99_latency": 33.56490408182144,
      "min_latency": 6.364378213882446,
      "max_latency": 33.709774017333984,
      "requests_per_second": 0.0353545278646545,
      "avg_cpu": 2.054100529100529,
      "peak_cpu": 6.3,
      "avg_memory_mb": 2003.3802548363096,
      "peak_memory_mb": 2013.0546875,
      "avg_gpu": 82.77645502645503,
      "peak_gpu": 100.0,
      "avg_power": 285.68916666666667,
      "peak_power": 299.7,
      "avg_correctness": 0.8229166666666666,
      "total_correct": 79.0,
      "accuracy_percentage": 82.29166666666666,
      "correctness_std": 0.3817392125376811,
      "total_tokens": 88399,
      "avg_tokens_per_response": 920.8229166666666,
      "tokens_per_second": 32.5552594657041
    },
    "timestamp": "2026-02-17T11:20:20.472241"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 13.174299250046412,
      "median_latency": 6.942508220672607,
      "p95_latency": 27.6193750500679,
      "p99_latency": 28.172080802917474,
      "min_latency": 1.9165141582489014,
      "max_latency": 30.370984315872192,
      "requests_per_second": 0.06810421957541334,
      "avg_cpu": 2.257142857142857,
      "peak_cpu": 6.4,
      "avg_memory_mb": 1949.1282242063492,
      "peak_memory_mb": 1950.2890625,
      "avg_gpu": 52.25396825396825,
      "peak_gpu": 100.0,
      "avg_power": 220.90912698412694,
      "peak_power": 299.01,
      "avg_correctness": 0.71875,
      "total_correct": 69.0,
      "accuracy_percentage": 71.875,
      "correctness_std": 0.4496092053105675,
      "total_tokens": 47439,
      "avg_tokens_per_response": 494.15625,
      "tokens_per_second": 33.65412575456284
    },
    "timestamp": "2026-02-17T11:45:05.705847"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 15.757891883452734,
      "median_latency": 12.01822543144226,
      "p95_latency": 29.41130781173706,
      "p99_latency": 33.60396443605423,
      "min_latency": 2.866264820098877,
      "max_latency": 34.32496738433838,
      "requests_per_second": 0.06341394078064255,
      "avg_cpu": 3.4819956616052057,
      "peak_cpu": 7.6,
      "avg_memory_mb": 1943.3150420281995,
      "peak_memory_mb": 1948.86328125,
      "avg_gpu": 82.35574837310195,
      "peak_gpu": 97.0,
      "avg_power": 288.07251626898045,
      "peak_power": 299.6,
      "avg_correctness": 0.6979166666666666,
      "total_correct": 67.0,
      "accuracy_percentage": 69.79166666666666,
      "correctness_std": 0.45916118417779567,
      "total_tokens": 52846,
      "avg_tokens_per_response": 550.4791666666666,
      "tokens_per_second": 34.90805327597746
    },
    "timestamp": "2026-02-17T12:10:21.578663"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 17.548683198789757,
      "median_latency": 26.444769382476807,
      "p95_latency": 28.705256164073944,
      "p99_latency": 29.493866086006165,
      "min_latency": 2.0046560764312744,
      "max_latency": 29.92618441581726,
      "requests_per_second": 0.05697127534930523,
      "avg_cpu": 4.382283464566929,
      "peak_cpu": 9.0,
      "avg_memory_mb": 1947.109375,
      "peak_memory_mb": 1947.109375,
      "avg_gpu": 89.81299212598425,
      "peak_gpu": 98.0,
      "avg_power": 296.5317125984252,
      "peak_power": 300.21,
      "avg_correctness": 0.7083333333333334,
      "total_correct": 68.0,
      "accuracy_percentage": 70.83333333333334,
      "correctness_std": 0.45452967144315476,
      "total_tokens": 63525,
      "avg_tokens_per_response": 661.71875,
      "tokens_per_second": 37.69896111004807
    },
    "timestamp": "2026-02-17T12:38:28.644933"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 19.013125369946163,
      "median_latency": 27.643290281295776,
      "p95_latency": 30.53668850660324,
      "p99_latency": 32.901747322082514,
      "min_latency": 3.2745039463043213,
      "max_latency": 34.35494899749756,
      "requests_per_second": 0.05255923681919354,
      "avg_cpu": 3.7331531531531534,
      "peak_cpu": 7.7,
      "avg_memory_mb": 1945.0956010698198,
      "peak_memory_mb": 1951.0625,
      "avg_gpu": 84.85765765765765,
      "peak_gpu": 96.0,
      "avg_power": 287.98133333333334,
      "peak_power": 299.8,
      "avg_correctness": 0.71875,
      "total_correct": 69.0,
      "accuracy_percentage": 71.875,
      "correctness_std": 0.4496092053105675,
      "total_tokens": 64062,
      "avg_tokens_per_response": 667.3125,
      "tokens_per_second": 35.07343571990809
    },
    "timestamp": "2026-02-17T13:08:57.165109"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 20.07184203217427,
      "median_latency": 26.9866441488266,
      "p95_latency": 28.363990008831024,
      "p99_latency": 30.321005117893215,
      "min_latency": 2.2459375858306885,
      "max_latency": 32.00479793548584,
      "requests_per_second": 0.04976934530179886,
      "avg_cpu": 2.6922413793103455,
      "peak_cpu": 6.7,
      "avg_memory_mb": 1951.0625,
      "peak_memory_mb": 1951.0625,
      "avg_gpu": 91.46551724137932,
      "peak_gpu": 98.0,
      "avg_power": 297.70038793103447,
      "peak_power": 299.92,
      "avg_correctness": 0.75,
      "total_correct": 72.0,
      "accuracy_percentage": 75.0,
      "correctness_std": 0.4330127018922193,
      "total_tokens": 71857,
      "avg_tokens_per_response": 748.5104166666666,
      "tokens_per_second": 37.252873389076676
    },
    "timestamp": "2026-02-17T13:41:08.071417"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 22.74750752747059,
      "median_latency": 29.03604292869568,
      "p95_latency": 30.334335803985596,
      "p99_latency": 31.401335954666138,
      "min_latency": 3.6860928535461426,
      "max_latency": 31.842272520065308,
      "requests_per_second": 0.0439324403622179,
      "avg_cpu": 2.9116822429906537,
      "peak_cpu": 9.7,
      "avg_memory_mb": 1950.0193973909657,
      "peak_memory_mb": 1954.68359375,
      "avg_gpu": 85.38317757009345,
      "peak_gpu": 100.0,
      "avg_power": 288.12543613707163,
      "peak_power": 300.07,
      "avg_correctness": 0.7604166666666666,
      "total_correct": 73.0,
      "accuracy_percentage": 76.04166666666666,
      "correctness_std": 0.42682919267808084,
      "total_tokens": 74616,
      "avg_tokens_per_response": 777.25,
      "tokens_per_second": 34.14648927153386
    },
    "timestamp": "2026-02-17T14:17:35.253019"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 25.003187308708828,
      "median_latency": 29.216797709465027,
      "p95_latency": 30.71465313434601,
      "p99_latency": 32.355995774269104,
      "min_latency": 2.568249464035034,
      "max_latency": 32.78998565673828,
      "requests_per_second": 0.039961572299212905,
      "avg_cpu": 3.439512855209743,
      "peak_cpu": 10.2,
      "avg_memory_mb": 1953.5591064783491,
      "peak_memory_mb": 1954.2890625,
      "avg_gpu": 91.22056833558864,
      "peak_gpu": 100.0,
      "avg_power": 296.7334235453315,
      "peak_power": 299.91,
      "avg_correctness": 0.7083333333333334,
      "total_correct": 68.0,
      "accuracy_percentage": 70.83333333333334,
      "correctness_std": 0.45452967144315476,
      "total_tokens": 82947,
      "avg_tokens_per_response": 864.03125,
      "tokens_per_second": 34.5280472656543
    },
    "timestamp": "2026-02-17T14:57:39.569362"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 25.674385490516823,
      "median_latency": 31.771989464759827,
      "p95_latency": 33.159847378730774,
      "p99_latency": 34.00375612974167,
      "min_latency": 5.146563768386841,
      "max_latency": 34.797672748565674,
      "requests_per_second": 0.03891771803730729,
      "avg_cpu": 3.3118181818181824,
      "peak_cpu": 9.2,
      "avg_memory_mb": 1963.640137987013,
      "peak_memory_mb": 1983.953125,
      "avg_gpu": 82.23246753246754,
      "peak_gpu": 100.0,
      "avg_power": 284.0115844155844,
      "peak_power": 299.58,
      "avg_correctness": 0.7083333333333334,
      "total_correct": 68.0,
      "accuracy_percentage": 70.83333333333334,
      "correctness_std": 0.45452967144315476,
      "total_tokens": 76699,
      "avg_tokens_per_response": 798.9479166666666,
      "tokens_per_second": 31.093229747327417
    },
    "timestamp": "2026-02-17T15:38:48.318714"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 3.6125361596544585,
      "median_latency": 2.5931416749954224,
      "p95_latency": 10.658517301082611,
      "p99_latency": 13.50973228216171,
      "min_latency": 0.6187648773193359,
      "max_latency": 13.959607124328613,
      "requests_per_second": 0.20952804420358706,
      "avg_cpu": 6.873469387755102,
      "peak_cpu": 12.1,
      "avg_memory_mb": 1983.37109375,
      "peak_memory_mb": 1983.37109375,
      "avg_gpu": 52.88775510204081,
      "peak_gpu": 94.0,
      "avg_power": 225.6239795918367,
      "peak_power": 298.47,
      "avg_correctness": 0.46875,
      "total_correct": 45.0,
      "accuracy_percentage": 46.875,
      "correctness_std": 0.4990224819584785,
      "total_tokens": 12575,
      "avg_tokens_per_response": 130.98958333333334,
      "tokens_per_second": 27.44599120687612
    },
    "timestamp": "2026-02-17T15:46:37.113719"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 4.398913842936357,
      "median_latency": 3.2051665782928467,
      "p95_latency": 8.362194001674652,
      "p99_latency": 26.81646982431411,
      "min_latency": 1.9120900630950928,
      "max_latency": 28.245251655578613,
      "requests_per_second": 0.22720311102333154,
      "avg_cpu": 4.17175572519084,
      "peak_cpu": 7.5,
      "avg_memory_mb": 1974.6394620706108,
      "peak_memory_mb": 1987.22265625,
      "avg_gpu": 78.12977099236642,
      "peak_gpu": 97.0,
      "avg_power": 272.90244274809163,
      "peak_power": 299.59,
      "avg_correctness": 0.3229166666666667,
      "total_correct": 31.0,
      "accuracy_percentage": 32.29166666666667,
      "correctness_std": 0.46759116015548835,
      "total_tokens": 12623,
      "avg_tokens_per_response": 131.48958333333334,
      "tokens_per_second": 29.874842400494938
    },
    "timestamp": "2026-02-17T15:53:41.650101"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 13.400668469568094,
      "median_latency": 5.287387132644653,
      "p95_latency": 28.272724509239197,
      "p99_latency": 29.93802771568297,
      "min_latency": 1.4124088287353516,
      "max_latency": 34.190858125686646,
      "requests_per_second": 0.07460688700653947,
      "avg_cpu": 5.974603174603175,
      "peak_cpu": 10.0,
      "avg_memory_mb": 1987.22265625,
      "peak_memory_mb": 1987.22265625,
      "avg_gpu": 86.51058201058201,
      "peak_gpu": 98.0,
      "avg_power": 294.7608994708995,
      "peak_power": 300.0,
      "avg_correctness": 0.34375,
      "total_correct": 33.0,
      "accuracy_percentage": 34.375,
      "correctness_std": 0.47495887979908324,
      "total_tokens": 47102,
      "avg_tokens_per_response": 490.6458333333333,
      "tokens_per_second": 36.6055582477294
    },
    "timestamp": "2026-02-17T16:15:10.401620"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 10.616313102344671,
      "median_latency": 4.772137522697449,
      "p95_latency": 28.93322503566742,
      "p99_latency": 29.975004839897156,
      "min_latency": 2.282683849334717,
      "max_latency": 30.09499740600586,
      "requests_per_second": 0.094010015998424,
      "avg_cpu": 6.496396396396396,
      "peak_cpu": 9.3,
      "avg_memory_mb": 1989.3500140765766,
      "peak_memory_mb": 1999.2109375,
      "avg_gpu": 76.36036036036036,
      "peak_gpu": 100.0,
      "avg_power": 279.7587387387387,
      "peak_power": 298.77,
      "avg_correctness": 0.3645833333333333,
      "total_correct": 35.0,
      "accuracy_percentage": 36.45833333333333,
      "correctness_std": 0.4813131271728301,
      "total_tokens": 33968,
      "avg_tokens_per_response": 353.8333333333333,
      "tokens_per_second": 33.26387732744236
    },
    "timestamp": "2026-02-17T16:32:13.576661"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 19.921948408087093,
      "median_latency": 27.669841766357422,
      "p95_latency": 29.485763370990753,
      "p99_latency": 30.418740510940548,
      "min_latency": 1.4351966381072998,
      "max_latency": 31.372436046600342,
      "requests_per_second": 0.05014327667051222,
      "avg_cpu": 5.026121372031662,
      "peak_cpu": 12.4,
      "avg_memory_mb": 2002.28125,
      "peak_memory_mb": 2002.28125,
      "avg_gpu": 88.8891820580475,
      "peak_gpu": 96.0,
      "avg_power": 295.55356200527706,
      "peak_power": 299.71,
      "avg_correctness": 0.34375,
      "total_correct": 33.0,
      "accuracy_percentage": 34.375,
      "correctness_std": 0.47495887979908324,
      "total_tokens": 69128,
      "avg_tokens_per_response": 720.0833333333334,
      "tokens_per_second": 36.107337809158004
    },
    "timestamp": "2026-02-17T17:04:10.102782"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 18.069159105420113,
      "median_latency": 28.75710701942444,
      "p95_latency": 30.74791568517685,
      "p99_latency": 30.963185226917265,
      "min_latency": 2.9551801681518555,
      "max_latency": 31.186931610107422,
      "requests_per_second": 0.05527907480089339,
      "avg_cpu": 7.074725274725275,
      "peak_cpu": 11.5,
      "avg_memory_mb": 2006.6490813873627,
      "peak_memory_mb": 2014.9140625,
      "avg_gpu": 84.91208791208791,
      "peak_gpu": 100.0,
      "avg_power": 286.43681318681314,
      "peak_power": 299.11,
      "avg_correctness": 0.3541666666666667,
      "total_correct": 34.0,
      "accuracy_percentage": 35.41666666666667,
      "correctness_std": 0.4782600118020415,
      "total_tokens": 57249,
      "avg_tokens_per_response": 596.34375,
      "tokens_per_second": 32.96533076329527
    },
    "timestamp": "2026-02-17T17:33:08.753051"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 24.137967348098755,
      "median_latency": 29.216591000556946,
      "p95_latency": 30.16028106212616,
      "p99_latency": 31.348542249202723,
      "min_latency": 1.0491507053375244,
      "max_latency": 33.17177200317383,
      "requests_per_second": 0.04139269169650245,
      "avg_cpu": 4.59375,
      "peak_cpu": 8.7,
      "avg_memory_mb": 2032.25390625,
      "peak_memory_mb": 2032.25390625,
      "avg_gpu": 90.03125,
      "peak_gpu": 98.0,
      "avg_power": 296.24375,
      "peak_power": 298.55,
      "avg_correctness": 0.3333333333333333,
      "total_correct": 32.0,
      "accuracy_percentage": 33.33333333333333,
      "correctness_std": 0.47140452079103173,
      "total_tokens": 80302,
      "avg_tokens_per_response": 836.4791666666666,
      "tokens_per_second": 34.624124256380625
    },
    "timestamp": "2026-02-17T18:11:50.015199"
  },
  {
    "framework": "langchain",
    "framework_name": "LangChain",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 20.09490883598725,
      "median_latency": 30.637418150901794,
      "p95_latency": 32.5793776512146,
      "p99_latency": 33.54128606319428,
      "min_latency": 1.2663965225219727,
      "max_latency": 33.623297691345215,
      "requests_per_second": 0.04971225856799641,
      "avg_cpu": 5.972,
      "peak_cpu": 9.8,
      "avg_memory_mb": 2049.8801041666666,
      "peak_memory_mb": 2053.453125,
      "avg_gpu": 84.45333333333333,
      "peak_gpu": 100.0,
      "avg_power": 285.0677333333333,
      "peak_power": 299.34,
      "avg_correctness": 0.375,
      "total_correct": 36.0,
      "accuracy_percentage": 37.5,
      "correctness_std": 0.4841229182759271,
      "total_tokens": 60932,
      "avg_tokens_per_response": 634.7083333333334,
      "tokens_per_second": 31.55278478192872
    },
    "timestamp": "2026-02-17T18:44:03.136261"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 14.989708180228869,
      "median_latency": 14.056853771209717,
      "p95_latency": 25.481520116329193,
      "p99_latency": 33.7018046855926,
      "min_latency": 4.28424072265625,
      "max_latency": 51.93873047828674,
      "requests_per_second": 0.06211214082262961,
      "avg_cpu": 4.662068965517241,
      "peak_cpu": 9.7,
      "avg_memory_mb": 2064.18299115245,
      "peak_memory_mb": 2077.078125,
      "avg_gpu": 21.32512315270936,
      "peak_gpu": 100.0,
      "avg_power": 175.14916256157636,
      "peak_power": 202.32,
      "avg_correctness": 0.3333333333333333,
      "total_correct": 32.0,
      "accuracy_percentage": 33.33333333333333,
      "correctness_std": 0.47140452079103173,
      "total_tokens": 37040,
      "avg_tokens_per_response": 385.8333333333333,
      "tokens_per_second": 23.96493433406459
    },
    "timestamp": "2026-02-17T19:11:09.455365"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 15.738202378153801,
      "median_latency": 13.182376146316528,
      "p95_latency": 31.59162348508835,
      "p99_latency": 41.95844365358352,
      "min_latency": 5.611982583999634,
      "max_latency": 44.3405921459198,
      "requests_per_second": 0.06346620807231608,
      "avg_cpu": 3.81969696969697,
      "peak_cpu": 19.7,
      "avg_memory_mb": 2080.16836085464,
      "peak_memory_mb": 2090.48046875,
      "avg_gpu": 27.587755102040816,
      "peak_gpu": 54.0,
      "avg_power": 193.27345528455285,
      "peak_power": 211.36,
      "avg_correctness": 0.34375,
      "total_correct": 33.0,
      "accuracy_percentage": 34.375,
      "correctness_std": 0.47495887979908324,
      "total_tokens": 39480,
      "avg_tokens_per_response": 411.25,
      "tokens_per_second": 26.100478069739985
    },
    "timestamp": "2026-02-17T19:36:24.087633"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 13.23465188841025,
      "median_latency": 12.197327852249146,
      "p95_latency": 22.762038111686707,
      "p99_latency": 27.951174473762503,
      "min_latency": 5.711665153503418,
      "max_latency": 31.322582483291626,
      "requests_per_second": 0.07544034000735282,
      "avg_cpu": 6.593518518518518,
      "peak_cpu": 9.8,
      "avg_memory_mb": 2088.3059895833335,
      "peak_memory_mb": 2093.35546875,
      "avg_gpu": 26.62037037037037,
      "peak_gpu": 50.0,
      "avg_power": 193.5775462962963,
      "peak_power": 206.0,
      "avg_correctness": 0.3541666666666667,
      "total_correct": 34.0,
      "accuracy_percentage": 35.41666666666667,
      "correctness_std": 0.4782600118020414,
      "total_tokens": 33479,
      "avg_tokens_per_response": 348.7395833333333,
      "tokens_per_second": 26.30903274068922
    },
    "timestamp": "2026-02-17T19:57:38.627062"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "phi2",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 14.365615626176199,
      "median_latency": 13.150798439979553,
      "p95_latency": 23.789131104946136,
      "p99_latency": 38.39041314125055,
      "min_latency": 4.661198139190674,
      "max_latency": 58.274027585983276,
      "requests_per_second": 0.06957337717330413,
      "avg_cpu": 5.016179775280898,
      "peak_cpu": 11.3,
      "avg_memory_mb": 2102.7744996488764,
      "peak_memory_mb": 2109.10546875,
      "avg_gpu": 27.429213483146068,
      "peak_gpu": 56.0,
      "avg_power": 195.54017977528088,
      "peak_power": 210.93,
      "avg_correctness": 0.4270833333333333,
      "total_correct": 41.0,
      "accuracy_percentage": 42.70833333333333,
      "correctness_std": 0.4946545862743237,
      "total_tokens": 35866,
      "avg_tokens_per_response": 373.6041666666667,
      "tokens_per_second": 25.992903601017975
    },
    "timestamp": "2026-02-17T20:20:40.476808"
  }
]