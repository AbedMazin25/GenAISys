[
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 27.736964638034504,
      "median_latency": 27.274762749671936,
      "p95_latency": 40.514261066913605,
      "p99_latency": 41.67466248273849,
      "min_latency": 15.72543978691101,
      "max_latency": 41.91973090171814,
      "requests_per_second": 0.03292705303371871,
      "avg_cpu": 3.968383110195674,
      "peak_cpu": 13.7,
      "avg_memory_mb": 1226.7824448056128,
      "peak_memory_mb": 1232.09375,
      "avg_gpu": 78.66941297631308,
      "peak_gpu": 98.0,
      "avg_power": 278.60883625128736,
      "peak_power": 299.96,
      "avg_correctness": 0.7916666666666666,
      "total_correct": 76.0,
      "accuracy_percentage": 79.16666666666666,
      "correctness_std": 0.4061164310337068,
      "total_tokens": 96444,
      "avg_tokens_per_response": 1004.625,
      "tokens_per_second": 33.07934065399966
    },
    "timestamp": "2026-02-17T22:10:39.128078"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 28.94469652076562,
      "median_latency": 27.640828609466553,
      "p95_latency": 41.790076076984406,
      "p99_latency": 43.8379829287529,
      "min_latency": 16.386314868927002,
      "max_latency": 44.2994544506073,
      "requests_per_second": 0.03452458460014749,
      "avg_cpu": 3.0357768052516407,
      "peak_cpu": 6.7,
      "avg_memory_mb": 1829.2361229827682,
      "peak_memory_mb": 1884.75,
      "avg_gpu": 86.1422319474836,
      "peak_gpu": 100.0,
      "avg_power": 294.01331509846824,
      "peak_power": 301.28,
      "avg_correctness": 0.8020833333333334,
      "total_correct": 77.0,
      "accuracy_percentage": 80.20833333333334,
      "correctness_std": 0.3984289895605266,
      "total_tokens": 98265,
      "avg_tokens_per_response": 1023.59375,
      "tokens_per_second": 35.33914901805722
    },
    "timestamp": "2026-02-17T22:57:01.776894"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 27.183506009479363,
      "median_latency": 25.854689955711365,
      "p95_latency": 39.82519471645355,
      "p99_latency": 42.80299227237701,
      "min_latency": 12.903501510620117,
      "max_latency": 43.85090947151184,
      "requests_per_second": 0.03675878140407828,
      "avg_cpu": 3.0073563218390804,
      "peak_cpu": 6.4,
      "avg_memory_mb": 1857.4994612068965,
      "peak_memory_mb": 1858.03125,
      "avg_gpu": 88.41426927502877,
      "peak_gpu": 98.0,
      "avg_power": 297.10297701149426,
      "peak_power": 300.4,
      "avg_correctness": 0.8229166666666666,
      "total_correct": 79.0,
      "accuracy_percentage": 82.29166666666666,
      "correctness_std": 0.3817392125376811,
      "total_tokens": 95857,
      "avg_tokens_per_response": 998.5104166666666,
      "tokens_per_second": 36.70402613594512
    },
    "timestamp": "2026-02-17T23:40:35.419841"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 28.580208693941433,
      "median_latency": 28.089906811714172,
      "p95_latency": 41.24693560600281,
      "p99_latency": 41.93232567310333,
      "min_latency": 14.337480306625366,
      "max_latency": 42.760579109191895,
      "requests_per_second": 0.0349773134452238,
      "avg_cpu": 3.088402625820569,
      "peak_cpu": 6.6,
      "avg_memory_mb": 1963.7159378419037,
      "peak_memory_mb": 1972.44140625,
      "avg_gpu": 85.38840262582058,
      "peak_gpu": 100.0,
      "avg_power": 293.2523741794311,
      "peak_power": 301.2,
      "avg_correctness": 0.8854166666666666,
      "total_correct": 85.0,
      "accuracy_percentage": 88.54166666666666,
      "correctness_std": 0.318518434404597,
      "total_tokens": 96287,
      "avg_tokens_per_response": 1002.9895833333334,
      "tokens_per_second": 35.08188103854441
    },
    "timestamp": "2026-02-18T00:26:22.085243"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 27.163299607733887,
      "median_latency": 26.077414989471436,
      "p95_latency": 40.6960226893425,
      "p99_latency": 41.10164147615433,
      "min_latency": 12.730181217193604,
      "max_latency": 41.894370794296265,
      "requests_per_second": 0.036786078856163126,
      "avg_cpu": 3.001267281105991,
      "peak_cpu": 6.5,
      "avg_memory_mb": 1968.8203125,
      "peak_memory_mb": 1968.8203125,
      "avg_gpu": 86.57373271889401,
      "peak_gpu": 100.0,
      "avg_power": 296.6397695852534,
      "peak_power": 301.31,
      "avg_correctness": 0.78125,
      "total_correct": 75.0,
      "accuracy_percentage": 78.125,
      "correctness_std": 0.41339864235384227,
      "total_tokens": 93572,
      "avg_tokens_per_response": 974.7083333333334,
      "tokens_per_second": 35.85569761175933
    },
    "timestamp": "2026-02-18T01:09:53.790479"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 29.252358372012775,
      "median_latency": 28.322966814041138,
      "p95_latency": 42.39417964220047,
      "p99_latency": 42.80973881483078,
      "min_latency": 15.53161358833313,
      "max_latency": 42.85504174232483,
      "requests_per_second": 0.034160894284739826,
      "avg_cpu": 2.801980198019801,
      "peak_cpu": 4.7,
      "avg_memory_mb": 1920.3015934405942,
      "peak_memory_mb": 1969.72265625,
      "avg_gpu": 81.11881188118812,
      "peak_gpu": 100.0,
      "avg_power": 291.4569306930693,
      "peak_power": 300.15,
      "avg_correctness": 0.8541666666666666,
      "total_correct": 82.0,
      "accuracy_percentage": 85.41666666666666,
      "correctness_std": 0.35293904887702954,
      "total_tokens": 97117,
      "avg_tokens_per_response": 1011.6354166666666,
      "tokens_per_second": 34.55837052344873
    },
    "timestamp": "2026-02-18T01:56:46.044686"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 26.696585391958553,
      "median_latency": 25.331297516822815,
      "p95_latency": 39.31812071800232,
      "p99_latency": 41.034392786026,
      "min_latency": 14.077836513519287,
      "max_latency": 41.640875577926636,
      "requests_per_second": 0.03742870788266419,
      "avg_cpu": 3.9502145922746785,
      "peak_cpu": 9.4,
      "avg_memory_mb": 1882.5170667918455,
      "peak_memory_mb": 1882.6015625,
      "avg_gpu": 86.50214592274678,
      "peak_gpu": 96.0,
      "avg_power": 296.3323175965665,
      "peak_power": 300.26,
      "avg_correctness": 0.9166666666666666,
      "total_correct": 88.0,
      "accuracy_percentage": 91.66666666666666,
      "correctness_std": 0.2763853991962833,
      "total_tokens": 91967,
      "avg_tokens_per_response": 957.9895833333334,
      "tokens_per_second": 35.85631226921852
    },
    "timestamp": "2026-02-18T02:39:32.941514"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "deepseek-r1-distill",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 29.14599331219991,
      "median_latency": 28.27614402770996,
      "p95_latency": 42.933685183525085,
      "p99_latency": 44.11839487552643,
      "min_latency": 16.193599462509155,
      "max_latency": 44.664685010910034,
      "requests_per_second": 0.034296504498967914,
      "avg_cpu": 3.9309110629067248,
      "peak_cpu": 10.7,
      "avg_memory_mb": 2025.0481883812365,
      "peak_memory_mb": 2042.82421875,
      "avg_gpu": 82.98698481561821,
      "peak_gpu": 100.0,
      "avg_power": 290.24888286334055,
      "peak_power": 299.99,
      "avg_correctness": 0.8645833333333334,
      "total_correct": 83.0,
      "accuracy_percentage": 86.45833333333334,
      "correctness_std": 0.3421680772011842,
      "total_tokens": 94008,
      "avg_tokens_per_response": 979.25,
      "tokens_per_second": 33.584852030614336
    },
    "timestamp": "2026-02-18T03:26:14.090069"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 9.58790701876084,
      "median_latency": 9.242544770240784,
      "p95_latency": 15.110898852348328,
      "p99_latency": 16.22678918838501,
      "min_latency": 4.2152955532073975,
      "max_latency": 16.668879985809326,
      "requests_per_second": 0.09200798366418377,
      "avg_cpu": 3.875,
      "peak_cpu": 5.4,
      "avg_memory_mb": 2022.99609375,
      "peak_memory_mb": 2022.99609375,
      "avg_gpu": 0.25,
      "peak_gpu": 1.0,
      "avg_power": 97.315,
      "peak_power": 108.45,
      "avg_correctness": 0.6354166666666666,
      "total_correct": 61.0,
      "accuracy_percentage": 63.541666666666664,
      "correctness_std": 0.4813131271728301,
      "total_tokens": 33943,
      "avg_tokens_per_response": 353.5729166666667,
      "tokens_per_second": 32.53153114076448
    },
    "timestamp": "2026-02-18T03:44:58.982093"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 10.737689514954885,
      "median_latency": 10.35697865486145,
      "p95_latency": 15.782296419143677,
      "p99_latency": 17.3992996096611,
      "min_latency": 5.03049373626709,
      "max_latency": 18.46945548057556,
      "requests_per_second": 0.09294939483980791,
      "avg_cpu": 5.440175953079178,
      "peak_cpu": 13.4,
      "avg_memory_mb": 1972.758568548387,
      "peak_memory_mb": 1981.46875,
      "avg_gpu": 79.88269794721407,
      "peak_gpu": 94.0,
      "avg_power": 287.76530791788855,
      "peak_power": 299.59,
      "avg_correctness": 0.6354166666666666,
      "total_correct": 61.0,
      "accuracy_percentage": 63.541666666666664,
      "correctness_std": 0.4813131271728301,
      "total_tokens": 34918,
      "avg_tokens_per_response": 363.7291666666667,
      "tokens_per_second": 33.8084059272543
    },
    "timestamp": "2026-02-18T04:02:13.808042"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 9.88152718047301,
      "median_latency": 9.491020560264587,
      "p95_latency": 15.534526705741882,
      "p99_latency": 16.236922621726972,
      "min_latency": 4.494462251663208,
      "max_latency": 22.243434190750122,
      "requests_per_second": 0.10098576541237994,
      "avg_cpu": 4.161661341853035,
      "peak_cpu": 11.0,
      "avg_memory_mb": 1975.9558581269969,
      "peak_memory_mb": 1981.30859375,
      "avg_gpu": 85.19871794871794,
      "peak_gpu": 96.0,
      "avg_power": 295.07926517571883,
      "peak_power": 300.54,
      "avg_correctness": 0.6770833333333334,
      "total_correct": 65.0,
      "accuracy_percentage": 67.70833333333334,
      "correctness_std": 0.46759116015548835,
      "total_tokens": 35028,
      "avg_tokens_per_response": 364.875,
      "tokens_per_second": 36.84718115484213
    },
    "timestamp": "2026-02-18T04:18:06.446120"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 10.734843596816063,
      "median_latency": 10.643043875694275,
      "p95_latency": 16.337718844413757,
      "p99_latency": 17.93552557229996,
      "min_latency": 5.0935609340667725,
      "max_latency": 17.984737396240234,
      "requests_per_second": 0.09312566868613195,
      "avg_cpu": 5.337861271676301,
      "peak_cpu": 10.7,
      "avg_memory_mb": 1974.2172371748554,
      "peak_memory_mb": 1987.68359375,
      "avg_gpu": 79.01445086705202,
      "peak_gpu": 96.0,
      "avg_power": 283.8281791907514,
      "peak_power": 300.32,
      "avg_correctness": 0.59375,
      "total_correct": 57.0,
      "accuracy_percentage": 59.375,
      "correctness_std": 0.4911323014219285,
      "total_tokens": 34701,
      "avg_tokens_per_response": 361.46875,
      "tokens_per_second": 33.66201905289026
    },
    "timestamp": "2026-02-18T04:35:19.319293"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 9.534871026873589,
      "median_latency": 9.230847835540771,
      "p95_latency": 15.071274280548096,
      "p99_latency": 16.276883435249328,
      "min_latency": 4.970075845718384,
      "max_latency": 16.966212272644043,
      "requests_per_second": 0.10464933362756479,
      "avg_cpu": 5.155409836065574,
      "peak_cpu": 11.3,
      "avg_memory_mb": 1979.9648949795082,
      "peak_memory_mb": 1987.54296875,
      "avg_gpu": 84.55737704918033,
      "peak_gpu": 94.0,
      "avg_power": 294.60255737704915,
      "peak_power": 299.59,
      "avg_correctness": 0.6458333333333334,
      "total_correct": 62.0,
      "accuracy_percentage": 64.58333333333334,
      "correctness_std": 0.4782600118020415,
      "total_tokens": 33547,
      "avg_tokens_per_response": 349.4479166666667,
      "tokens_per_second": 36.56949161670746
    },
    "timestamp": "2026-02-18T04:50:38.674865"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 10.835436925292015,
      "median_latency": 10.751028895378113,
      "p95_latency": 15.120911955833435,
      "p99_latency": 16.547178614139554,
      "min_latency": 5.511201858520508,
      "max_latency": 17.219656705856323,
      "requests_per_second": 0.0921125114155415,
      "avg_cpu": 4.945275590551181,
      "peak_cpu": 10.8,
      "avg_memory_mb": 1988.394792691929,
      "peak_memory_mb": 2000.8359375,
      "avg_gpu": 76.94094488188976,
      "peak_gpu": 100.0,
      "avg_power": 283.6109842519685,
      "peak_power": 299.53,
      "avg_correctness": 0.5833333333333334,
      "total_correct": 56.0,
      "accuracy_percentage": 58.333333333333336,
      "correctness_std": 0.4930066485916347,
      "total_tokens": 33815,
      "avg_tokens_per_response": 352.2395833333333,
      "tokens_per_second": 32.44567264079725
    },
    "timestamp": "2026-02-18T05:08:02.883933"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 10.060784655312697,
      "median_latency": 9.462429761886597,
      "p95_latency": 16.067977488040924,
      "p99_latency": 18.172005701065057,
      "min_latency": 4.802955389022827,
      "max_latency": 20.80545401573181,
      "requests_per_second": 0.0991902205223714,
      "avg_cpu": 2.680817610062893,
      "peak_cpu": 5.6,
      "avg_memory_mb": 2010.909787735849,
      "peak_memory_mb": 2013.578125,
      "avg_gpu": 84.80188679245283,
      "peak_gpu": 98.0,
      "avg_power": 294.66751572327047,
      "peak_power": 300.13,
      "avg_correctness": 0.6041666666666666,
      "total_correct": 58.0,
      "accuracy_percentage": 60.416666666666664,
      "correctness_std": 0.4890289414293959,
      "total_tokens": 35070,
      "avg_tokens_per_response": 365.3125,
      "tokens_per_second": 36.2354274345788
    },
    "timestamp": "2026-02-18T05:24:12.727783"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "metamath-mistral",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 11.540730106333891,
      "median_latency": 10.911559820175171,
      "p95_latency": 18.12864649295807,
      "p99_latency": 25.893150544166563,
      "min_latency": 6.032559394836426,
      "max_latency": 26.66642665863037,
      "requests_per_second": 0.08653515969676749,
      "avg_cpu": 2.4414634146341463,
      "peak_cpu": 5.6,
      "avg_memory_mb": 2006.9379234417345,
      "peak_memory_mb": 2015.96875,
      "avg_gpu": 75.94850948509485,
      "peak_gpu": 100.0,
      "avg_power": 281.58734417344175,
      "peak_power": 299.83,
      "avg_correctness": 0.65625,
      "total_correct": 63.0,
      "accuracy_percentage": 65.625,
      "correctness_std": 0.47495887979908324,
      "total_tokens": 34523,
      "avg_tokens_per_response": 359.6145833333333,
      "tokens_per_second": 31.119305398036502
    },
    "timestamp": "2026-02-18T05:42:44.109303"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 12.146766908466816,
      "median_latency": 10.726704597473145,
      "p95_latency": 22.023971498012543,
      "p99_latency": 26.17005054950714,
      "min_latency": 4.942957639694214,
      "max_latency": 27.350255966186523,
      "requests_per_second": 0.07128182526143964,
      "avg_cpu": 2.5218181818181815,
      "peak_cpu": 8.4,
      "avg_memory_mb": 2018.6578835227272,
      "peak_memory_mb": 2021.875,
      "avg_gpu": 72.8340909090909,
      "peak_gpu": 100.0,
      "avg_power": 268.257881548975,
      "peak_power": 299.39,
      "avg_correctness": 0.21875,
      "total_correct": 21.0,
      "accuracy_percentage": 21.875,
      "correctness_std": 0.41339864235384227,
      "total_tokens": 42906,
      "avg_tokens_per_response": 446.9375,
      "tokens_per_second": 31.85852077778468
    },
    "timestamp": "2026-02-18T06:06:30.135280"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 512,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 13.303825850288073,
      "median_latency": 11.167253613471985,
      "p95_latency": 27.078275859355927,
      "p99_latency": 28.655076742172234,
      "min_latency": 5.308152675628662,
      "max_latency": 30.778687000274658,
      "requests_per_second": 0.07506210767521611,
      "avg_cpu": 2.654046997389034,
      "peak_cpu": 6.9,
      "avg_memory_mb": 2028.2916734660575,
      "peak_memory_mb": 2039.3203125,
      "avg_gpu": 79.81723237597912,
      "peak_gpu": 95.0,
      "avg_power": 289.19506527415143,
      "peak_power": 299.7,
      "avg_correctness": 0.2604166666666667,
      "total_correct": 25.0,
      "accuracy_percentage": 26.041666666666668,
      "correctness_std": 0.43886196735293526,
      "total_tokens": 43946,
      "avg_tokens_per_response": 457.7708333333333,
      "tokens_per_second": 34.36124358224008
    },
    "timestamp": "2026-02-18T06:27:51.082060"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 11.727557229499022,
      "median_latency": 10.760193943977356,
      "p95_latency": 22.148647248744965,
      "p99_latency": 27.12807717323303,
      "min_latency": 3.411391019821167,
      "max_latency": 27.965269565582275,
      "requests_per_second": 0.08514612324202163,
      "avg_cpu": 2.706865671641791,
      "peak_cpu": 5.6,
      "avg_memory_mb": 2041.1362639925374,
      "peak_memory_mb": 2047.1953125,
      "avg_gpu": 84.72835820895523,
      "peak_gpu": 94.0,
      "avg_power": 295.65029850746265,
      "peak_power": 299.36,
      "avg_correctness": 0.2708333333333333,
      "total_correct": 26.0,
      "accuracy_percentage": 27.083333333333332,
      "correctness_std": 0.4443901876604488,
      "total_tokens": 41564,
      "avg_tokens_per_response": 432.9583333333333,
      "tokens_per_second": 36.86472360866028
    },
    "timestamp": "2026-02-18T06:46:40.562488"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 1024,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 13.059572344024977,
      "median_latency": 11.72698974609375,
      "p95_latency": 24.505804359912872,
      "p99_latency": 30.434565412998197,
      "min_latency": 5.869552373886108,
      "max_latency": 31.055180072784424,
      "requests_per_second": 0.0765570092663145,
      "avg_cpu": 2.8748663101604275,
      "peak_cpu": 6.6,
      "avg_memory_mb": 2046.4392860127004,
      "peak_memory_mb": 2054.66796875,
      "avg_gpu": 82.32085561497327,
      "peak_gpu": 100.0,
      "avg_power": 288.0843315508022,
      "peak_power": 300.16,
      "avg_correctness": 0.375,
      "total_correct": 36.0,
      "accuracy_percentage": 37.5,
      "correctness_std": 0.4841229182759271,
      "total_tokens": 43188,
      "avg_tokens_per_response": 449.875,
      "tokens_per_second": 34.44108454368323
    },
    "timestamp": "2026-02-18T07:07:36.539729"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 13.441439347962538,
      "median_latency": 12.523423314094543,
      "p95_latency": 21.9420046210289,
      "p99_latency": 23.381547558307645,
      "min_latency": 4.9268739223480225,
      "max_latency": 24.179197311401367,
      "requests_per_second": 0.07433010930376648,
      "avg_cpu": 2.6775943396226416,
      "peak_cpu": 18.4,
      "avg_memory_mb": 2057.955852004717,
      "peak_memory_mb": 2060.375,
      "avg_gpu": 86.40189125295508,
      "peak_gpu": 95.0,
      "avg_power": 296.02186320754714,
      "peak_power": 300.04,
      "avg_correctness": 0.46875,
      "total_correct": 45.0,
      "accuracy_percentage": 46.875,
      "correctness_std": 0.4990224819584785,
      "total_tokens": 47943,
      "avg_tokens_per_response": 499.40625,
      "tokens_per_second": 37.120921149484126
    },
    "timestamp": "2026-02-18T07:29:10.082034"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 2048,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 14.72722765058279,
      "median_latency": 13.647732019424438,
      "p95_latency": 25.43418312072754,
      "p99_latency": 29.443571257591234,
      "min_latency": 6.6039323806762695,
      "max_latency": 34.34482955932617,
      "requests_per_second": 0.06780543805726744,
      "avg_cpu": 2.56963906581741,
      "peak_cpu": 5.9,
      "avg_memory_mb": 2060.1358728105097,
      "peak_memory_mb": 2069.05859375,
      "avg_gpu": 79.96178343949045,
      "peak_gpu": 94.0,
      "avg_power": 286.3915711252654,
      "peak_power": 299.68,
      "avg_correctness": 0.40625,
      "total_correct": 39.0,
      "accuracy_percentage": 40.625,
      "correctness_std": 0.4911323014219285,
      "total_tokens": 47678,
      "avg_tokens_per_response": 496.6458333333333,
      "tokens_per_second": 33.6752882884833
    },
    "timestamp": "2026-02-18T07:52:47.904433"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "fixed",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 13.707129475971064,
      "median_latency": 12.822276830673218,
      "p95_latency": 23.507341742515564,
      "p99_latency": 28.759604263305643,
      "min_latency": 5.892493724822998,
      "max_latency": 35.641170024871826,
      "requests_per_second": 0.07291251283059039,
      "avg_cpu": 4.316705336426915,
      "peak_cpu": 10.5,
      "avg_memory_mb": 2068.6874637470996,
      "peak_memory_mb": 2072.921875,
      "avg_gpu": 85.68677494199535,
      "peak_gpu": 95.0,
      "avg_power": 295.3441531322506,
      "peak_power": 300.33,
      "avg_correctness": 0.3541666666666667,
      "total_correct": 34.0,
      "accuracy_percentage": 35.41666666666667,
      "correctness_std": 0.4782600118020415,
      "total_tokens": 47440,
      "avg_tokens_per_response": 494.1666666666667,
      "tokens_per_second": 36.03093342378342
    },
    "timestamp": "2026-02-18T08:14:46.559727"
  },
  {
    "framework": "langchain_reasoning",
    "framework_name": "LangChain-Reasoning",
    "model": "mistral-7b-quantized",
    "concurrent_requests": 1,
    "context_length": 4096,
    "context_strategy": "adaptive",
    "total_requests": 96,
    "stats": {
      "total_requests": 96,
      "successful_requests": 96,
      "failed_requests": 0,
      "avg_latency": 14.50091677904129,
      "median_latency": 13.116905808448792,
      "p95_latency": 22.77737832069397,
      "p99_latency": 28.377490186691283,
      "min_latency": 6.752081871032715,
      "max_latency": 28.771684885025024,
      "requests_per_second": 0.06888621530064129,
      "avg_cpu": 6.462608695652174,
      "peak_cpu": 12.1,
      "avg_memory_mb": 2082.0242017663045,
      "peak_memory_mb": 2099.91015625,
      "avg_gpu": 76.95217391304348,
      "peak_gpu": 100.0,
      "avg_power": 285.521152173913,
      "peak_power": 300.67,
      "avg_correctness": 0.375,
      "total_correct": 36.0,
      "accuracy_percentage": 37.5,
      "correctness_std": 0.4841229182759271,
      "total_tokens": 44350,
      "avg_tokens_per_response": 461.9791666666667,
      "tokens_per_second": 31.823996339410847
    },
    "timestamp": "2026-02-18T08:38:02.175062"
  }
]